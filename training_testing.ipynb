{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83f529d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics  import r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f8f7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Finder:\n",
    "    def __init__(self):\n",
    "        self.clf = RandomForestClassifier()\n",
    "        self.DecisionTreeReg = DecisionTreeRegressor()\n",
    "    \n",
    "    def get_best_params_for_random_forest(self,train_x,train_y):\n",
    "            #get the parameters for Random Forest Algorithm which give the best accuracy.\n",
    "            #Use Hyper Parameter Tuning.\n",
    "            # output will be The model with the best parameters\n",
    "            \n",
    "            # initializing with different combination of parameters\n",
    "            self.param_grid = {\"n_estimators\": [50, 100, 130],\"criterion\": ['squared_error', 'absolute_error', 'poisson'],\n",
    "                          \"max_depth\": range(2, 4, 1), \n",
    "                          \"max_features\": ['sqrt', 'log2']\n",
    "                             }\n",
    "            \n",
    "            #Creating an object of the Grid Search class\n",
    "            self.grid = GridSearchCV(estimator=self.clf, param_grid=self.param_grid, cv=5)\n",
    "            \n",
    "            self.grid.fit(train_x, train_y)\n",
    "            \n",
    "            #extracting the best parameters\n",
    "            self.criterion = self.grid.best_params_['criterion']\n",
    "            self.max_depth = self.grid.best_params_['max_depth']\n",
    "            self.max_features = self.grid.best_params_['max_features']\n",
    "            self.n_estimators = self.grid.best_params_['n_estimators']\n",
    "            \n",
    "            #creating a new model with the best parameters\n",
    "            self.clf = RandomForestClassifier(n_estimators=self.n_estimators, criterion=self.criterion,\n",
    "                                              max_depth=self.max_depth, max_features=self.max_features)\n",
    "            # training the mew model\n",
    "            self.clf.fit(train_x, train_y)\n",
    "            \n",
    "            return self.clf\n",
    "        \n",
    "        ###### for Decision Tree  ############\n",
    "        \n",
    "    def get_best_params_for_DecisionTreeRegressor(self, train_x, train_y):\n",
    "        #get the parameters for DecisionTreeRegressor Algorithm which gives best accuracy\n",
    "        #Output will be The model with the best parameters\n",
    "        \n",
    "        self.param_grid_decisionTree = {\"criterion\": [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "                              \"splitter\": [\"best\", \"random\"],\n",
    "                              \"max_features\": [ \"sqrt\", \"log2\"],\n",
    "                              'max_depth': range(2, 16, 2),\n",
    "                              'min_samples_split': range(2, 16, 2)\n",
    "                              }\n",
    "        # Creating an object of the Grid Search class\n",
    "        self.grid = GridSearchCV(self.DecisionTreeReg, self.param_grid_decisionTree, verbose=3,cv=5)\n",
    "        \n",
    "        self.grid.fit(train_x, train_y)\n",
    "\n",
    "        # extracting the best parameters\n",
    "        self.criterion = self.grid.best_params_['criterion']\n",
    "        self.splitter = self.grid.best_params_['splitter']\n",
    "        self.max_features = self.grid.best_params_['max_features']\n",
    "        self.max_depth  = self.grid.best_params_['max_depth']\n",
    "        self.min_samples_split = self.grid.best_params_['min_samples_split']\n",
    "        \n",
    "        # creating a new model with the best parameters\n",
    "        self.decisionTreeReg = DecisionTreeRegressor(criterion=self.criterion,splitter=self.splitter,\n",
    "                                                     max_features=self.max_features,max_depth=self.max_depth,\n",
    "                                                     min_samples_split=self.min_samples_split)\n",
    "        # training the new models\n",
    "        self.decisionTreeReg.fit(train_x, train_y)\n",
    "        \n",
    "        return self.decisionTreeReg\n",
    "    \n",
    "    def get_best_params_for_xgboost(self,train_x,train_y):\n",
    "        #get the parameters for XGBoost Algorithm which give the best accuracy.Use Hyper Parameter Tuning.\n",
    "        #output will be The model with the best parameters\n",
    "        \n",
    "        # initializing with different combination of parameters\n",
    "        self.param_grid_xgboost = {\n",
    "                           'n_estimators' : [ 50, 200],'subsample' : [0.7, 0.8],\n",
    "                            'max_depth' :[ 5,7],'learning_rate': [0.5, 0.01]\n",
    "\n",
    "                            }\n",
    "        self.grid= GridSearchCV(XGBRegressor(objective='reg:linear'),self.param_grid_xgboost, verbose=3,cv=5)\n",
    "        \n",
    "        self.grid.fit(train_x, train_y)\n",
    "        \n",
    "        # extracting the best parameters\n",
    "        self.learning_rate = self.grid.best_params_['learning_rate']\n",
    "        self.max_depth = self.grid.best_params_['max_depth']\n",
    "        self.n_estimators = self.grid.best_params_['n_estimators']\n",
    "        \n",
    "        # creating a new model with the best parameters\n",
    "        self.xgb = XGBRegressor(objective='reg:linear',learning_rate=self.learning_rate, \n",
    "                                max_depth=self.max_depth, n_estimators=self.n_estimators)\n",
    "        \n",
    "        # training the mew model\n",
    "        self.xgb.fit(train_x, train_y)\n",
    "        \n",
    "        return self.xgb\n",
    "    \n",
    "    def get_best_model(self,train_x,train_y,test_x,test_y):\n",
    "            #Find out the Model which has the best AUC score.\n",
    "            #Output: The best model name and the model object\n",
    "            ## for decision tree\n",
    "            self.decisionTreeReg= self.get_best_params_for_DecisionTreeRegressor(train_x, train_y)\n",
    "            self.prediction_decisionTreeReg = self.decisionTreeReg.predict(test_x) # Predictions using the decisionTreeReg Model\n",
    "            self.decisionTreeReg_error = r2_score(test_y,self.prediction_decisionTreeReg)\n",
    "            \n",
    "            # create best model for XGBoost\n",
    "            self.xgboost = self.get_best_params_for_xgboost(train_x, train_y)\n",
    "            self.prediction_xgboost = self.xgboost.predict(test_x)  # Predictions using the XGBoost Model\n",
    "            self.prediction_xgboost_error = r2_score(test_y,self.prediction_xgboost)\n",
    "            \n",
    "             #comparing the two models\n",
    "            if(self.decisionTreeReg_error <  self.prediction_xgboost_error):\n",
    "                return 'XGBoost',self.xgboost\n",
    "            else:\n",
    "                return 'DecisionTreeReg',self.decisionTreeReg\n",
    "\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b193ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"D:/cdac/CDAC_PROJECT/Untitled Folder/model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69836464",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e96c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import os\n",
    "import shutil\n",
    "\n",
    "class modelOperation:\n",
    "        \n",
    "    def save_model(model,filename):\n",
    "        path = os.path.join(\"D:/cdac/CDAC_PROJECT/Untitled Folder/model\",filename)  #create seperate directory for each cluster\n",
    "        if os.path.isdir(path):   #remove previously existing models for each clusters\n",
    "            shutil.rmtree(model_dir)\n",
    "            os.makedirs(path)\n",
    "        else:\n",
    "            os.makedirs(path) \n",
    "            with open(path +'/' + filename+'.sav','wb') as f:\n",
    "                \n",
    "                pickle.dump(model, f)\n",
    "        return 'success'\n",
    "    \n",
    "    def load_model(filename):\n",
    "        with open(model_dir + filename + '/' + filename + '.sav','rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bf19d2",
   "metadata": {},
   "source": [
    "## clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fddfbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from kneed import KneeLocator\n",
    "import matplotlib.pyplot as plt\n",
    "class KMeansClustering:\n",
    "    \n",
    "    def elbow_plot(data):\n",
    "        ss=[]\n",
    "        \n",
    "        for i in range(1,11):\n",
    "            kmeans=KMeans(n_clusters=i,init='k-means++',random_state=7)\n",
    "            kmeans.fit(data)\n",
    "            ss.append(kmeans.inertia_)\n",
    "            \n",
    "        plt.plot(range(1,11),ss) # creating the graph between SS and the number of clusters\n",
    "        plt.title('The Elbow Method')\n",
    "        plt.xlabel('Number of clusters')\n",
    "        plt.ylabel('SS')\n",
    "        \n",
    "        plt.savefig('K-Means_Elbow.PNG')\n",
    "        \n",
    "        kn = KneeLocator(range(1, 11), ss, curve='convex', direction='decreasing') #Xaxis,Yaxis,curveshape,direction\n",
    "        \n",
    "        return kn.knee\n",
    "    \n",
    "    def create_cluster(data,number_of_clusters):\n",
    "        kmeans = KMeans(n_clusters=number_of_clusters, init='k-means++', random_state=7)\n",
    "        \n",
    "        y_kmeans = kmeans.fit_predict(data)  #divide data into clusters\n",
    "        save_model = modelOperation.save_model(kmeans, 'KMeans')\n",
    "        \n",
    "        data['Cluster']=y_kmeans  # create a new column in dataset for storing the cluster information\n",
    "        return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4daecaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import preprocessor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84a21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/cdac/CDAC_PROJECT/Untitled Folder/Training_Batch_Files/visibility_08012008_120010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f394a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainModel:\n",
    "    model_dir = \"model/\"\n",
    "    \n",
    "    def trainingModel():\n",
    "            \n",
    "        ### preprocessing #####\n",
    "        #removing unwanted columns as seen in the EDA part\n",
    "        data = preprocessor.dropUnnecessaryCol(data,['DATE','Precip','WETBULBTEMPF','DewPointTempF','StationPressure'])\n",
    "\n",
    "        # create separate features and labels\n",
    "        X, Y = preprocessor.separate_label_feature(data, label_column_name='VISIBILITY')\n",
    "\n",
    "        #kmeans=KMeansClustering() # object initialization.\n",
    "        number_of_clusters=KMeansClustering.elbow_plot(X)  #  using the elbow plot to find the number of optimum clusters\n",
    "\n",
    "        # Divide the data into clusters\n",
    "        X = KMeansClustering.create_cluster(X,number_of_clusters)\n",
    "\n",
    "        #create a new column in the dataset consisting of the corresponding cluster assignments.\n",
    "        X['Labels']=Y\n",
    "\n",
    "         # getting the unique clusters from our dataset\n",
    "        list_of_clusters=X['Cluster'].unique()\n",
    "\n",
    "        ##parsing all the clusters and looking for the best ML algorithm to fit on individual cluster\n",
    "\n",
    "        for i in list_of_clusters:\n",
    "            cluster_data=X[X['Cluster']==i] # filter the data for one cluster\n",
    "\n",
    "            # Prepare the feature and Label columns\n",
    "            cluster_features=cluster_data.drop(['Labels','Cluster'],axis=1)\n",
    "            cluster_label= cluster_data['Labels']\n",
    "\n",
    "            # splitting the data into training and test set for each cluster one by one\n",
    "            x_train, x_test, y_train, y_test = train_test_split(cluster_features, cluster_label, test_size=0.3, random_state=7)\n",
    "\n",
    "            x_train_scaled = preprocessor.standardScaling(x_train)\n",
    "            x_test_scaled = preprocessor.standardScaling(x_test)\n",
    "\n",
    "            model_finder=Model_Finder()\n",
    "\n",
    "            #getting the best model for each of the clusters\n",
    "            best_model_name,best_model=model_finder.get_best_model(x_train_scaled,y_train,x_test_scaled,y_test)\n",
    "\n",
    "            #saving the best model to the directory.\n",
    "            #file_op = modelOperation()\n",
    "            save_model=modelOperation.save_model(best_model,best_model_name+str(i))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31bc92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
